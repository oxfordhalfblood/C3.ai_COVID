# -*- coding: utf-8 -*-
"""economictracker.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UtCjFhzMqfY0W_ouszVdswZDw3TYJakE
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
appletrackingdata = pd.read_csv('/content/drive/My Drive/c3ai_datasets/applemobilitytrends-2020-09-30.csv')

import seaborn as sns
sns.lineplot(data=appletrackingdata)

import pandas as pd
from scipy import stats
employment_national_data = pd.read_csv('/content/drive/My Drive/c3ai_datasets/Employment Combined - National - Daily.csv')

list(employment_national_data.columns)

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt #Data Visualization 
import seaborn as sns  #Python library for Visualization
from scipy import stats

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory

# import os
# print(os.listdir("../input"))

employment_national_data.head(10)
# employment_national_data.shape
# employment_national_data.info()

employment_national_data.tail(10)
employment_national_data = employment_national_data[:-53]  # exclude last 53 rows with incomplete data
employment_national_data

list(employment_national_data.columns)

employment_national_data.tail(10)

### Feature sleection for the model
#Considering only few features
X = employment_national_data.iloc[:, 1:10].values
X
### Get all the features columns except the first and last
features = list(employment_national_data.columns)[1:-2]
# features
# # ### Get the features data
data = employment_national_data[features]
# data

# to figure out K for KMeans, I will use ELBOW Method on KMEANS++ Calculation
from sklearn.cluster import KMeans
wcss=[]

#we always assume the max number of cluster would be 10
#you can judge the number of clusters by doing averaging
###Static code to get max no of clusters

for i in range(1,11):
    kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)
    kmeans.fit(X)
    wcss.append(kmeans.inertia_)

    #inertia_ is the formula used to segregate the data points into clusters

#Visualizing the ELBOW method to get the optimal value of K 
plt.plot(range(1,11), wcss)
plt.title('The Elbow Method')
plt.xlabel('no of clusters')
plt.ylabel('wcss')
plt.show()

## elbow k=3

#Model Build
kmeansmodel = KMeans(n_clusters= 3, init='k-means++', random_state=0)
y_kmeans= kmeansmodel.fit_predict(X)
data['cluster'] = y_kmeans
data.head(10)
#Lets analyze the clusters
# data.groupby(['cluster']).mean()

#For unsupervised learning we use "fit_predict()" wherein for supervised learning we use "fit_tranform()"
#y_kmeans is the final model . it is used in BFS industry(credit card) and retail for customer segmenattion.

#Visualizing all the clusters 

plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')
plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')
plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')
plt.scatter(kmeansmodel.cluster_centers_[:, 0], kmeansmodel.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')
plt.title('Clusters of economic levels')
plt.xlabel('clusters')
plt.ylabel('features')
plt.legend()
plt.show()

#Scatter plot of emp_combined and month
sns.lmplot('emp_combined', 'month', 
           data=data, 
           fit_reg=False, 
           hue="cluster",  
           scatter_kws={"marker": "D", 
                        "s": 100})
plt.title('Clusters Wattage vs Duration')
plt.xlabel('emp_combined')
plt.ylabel('month')